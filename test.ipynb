{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa14040f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moin!\n"
     ]
    }
   ],
   "source": [
    "print(\"Moin!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99872330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22301ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of the current working directory:  /home/franzi/mypython/CLIP_img_obj_detect\n",
      "data\n",
      "old\n",
      ".gitignore\n",
      "test.py\n",
      ".git\n",
      "boundingbox.ipynb\n",
      ".venv\n",
      "test.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "print(\"Contents of the current working directory: \", current_dir)\n",
    "for item in os.listdir(current_dir):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589420a",
   "metadata": {},
   "source": [
    "## IMG to BOX mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30bd546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image to bounding box mapping:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data/images/img__00001_.png': 'data/bounding_boxes/bounding_boxes_00000.json',\n",
       " 'data/images/img__00002_.png': 'data/bounding_boxes/bounding_boxes_00001.json',\n",
       " 'data/images/img__00003_.png': 'data/bounding_boxes/bounding_boxes_00002.json',\n",
       " 'data/images/img__00004_.png': 'data/bounding_boxes/bounding_boxes_00003.json',\n",
       " 'data/images/img__00005_.png': 'data/bounding_boxes/bounding_boxes_00004.json',\n",
       " 'data/images/img__00006_.png': 'data/bounding_boxes/bounding_boxes_00005.json',\n",
       " 'data/images/img__00007_.png': 'data/bounding_boxes/bounding_boxes_00006.json',\n",
       " 'data/images/img__00008_.png': 'data/bounding_boxes/bounding_boxes_00007.json',\n",
       " 'data/images/img__00009_.png': 'data/bounding_boxes/bounding_boxes_00008.json',\n",
       " 'data/images/img__00010_.png': 'data/bounding_boxes/bounding_boxes_00009.json',\n",
       " 'data/images/img__00011_.png': 'data/bounding_boxes/bounding_boxes_00010.json',\n",
       " 'data/images/img__00012_.png': 'data/bounding_boxes/bounding_boxes_00011.json',\n",
       " 'data/images/img__00013_.png': 'data/bounding_boxes/bounding_boxes_00012.json',\n",
       " 'data/images/img__00014_.png': 'data/bounding_boxes/bounding_boxes_00013.json',\n",
       " 'data/images/img__00015_.png': 'data/bounding_boxes/bounding_boxes_00014.json',\n",
       " 'data/images/img__00016_.png': 'data/bounding_boxes/bounding_boxes_00015.json',\n",
       " 'data/images/img__00017_.png': 'data/bounding_boxes/bounding_boxes_00016.json',\n",
       " 'data/images/img__00018_.png': 'data/bounding_boxes/bounding_boxes_00017.json',\n",
       " 'data/images/img__00019_.png': 'data/bounding_boxes/bounding_boxes_00018.json',\n",
       " 'data/images/img__00020_.png': 'data/bounding_boxes/bounding_boxes_00019.json',\n",
       " 'data/images/img__00021_.png': 'data/bounding_boxes/bounding_boxes_00020.json',\n",
       " 'data/images/img__00022_.png': 'data/bounding_boxes/bounding_boxes_00021.json',\n",
       " 'data/images/img__00023_.png': 'data/bounding_boxes/bounding_boxes_00022.json',\n",
       " 'data/images/img__00024_.png': 'data/bounding_boxes/bounding_boxes_00023.json',\n",
       " 'data/images/img__00025_.png': 'data/bounding_boxes/bounding_boxes_00024.json',\n",
       " 'data/images/img__00026_.png': 'data/bounding_boxes/bounding_boxes_00025.json',\n",
       " 'data/images/img__00027_.png': 'data/bounding_boxes/bounding_boxes_00026.json',\n",
       " 'data/images/img__00028_.png': 'data/bounding_boxes/bounding_boxes_00027.json',\n",
       " 'data/images/img__00029_.png': 'data/bounding_boxes/bounding_boxes_00028.json',\n",
       " 'data/images/img__00030_.png': 'data/bounding_boxes/bounding_boxes_00029.json',\n",
       " 'data/images/img__00031_.png': 'data/bounding_boxes/bounding_boxes_00030.json',\n",
       " 'data/images/img__00032_.png': 'data/bounding_boxes/bounding_boxes_00031.json',\n",
       " 'data/images/img__00033_.png': 'data/bounding_boxes/bounding_boxes_00032.json',\n",
       " 'data/images/img__00034_.png': 'data/bounding_boxes/bounding_boxes_00033.json',\n",
       " 'data/images/img__00035_.png': 'data/bounding_boxes/bounding_boxes_00034.json',\n",
       " 'data/images/img__00036_.png': 'data/bounding_boxes/bounding_boxes_00035.json',\n",
       " 'data/images/img__00037_.png': 'data/bounding_boxes/bounding_boxes_00036.json',\n",
       " 'data/images/img__00038_.png': 'data/bounding_boxes/bounding_boxes_00037.json',\n",
       " 'data/images/img__00039_.png': 'data/bounding_boxes/bounding_boxes_00038.json',\n",
       " 'data/images/img__00040_.png': 'data/bounding_boxes/bounding_boxes_00039.json',\n",
       " 'data/images/img__00041_.png': 'data/bounding_boxes/bounding_boxes_00040.json',\n",
       " 'data/images/img__00042_.png': 'data/bounding_boxes/bounding_boxes_00041.json',\n",
       " 'data/images/img__00043_.png': 'data/bounding_boxes/bounding_boxes_00042.json',\n",
       " 'data/images/img__00044_.png': 'data/bounding_boxes/bounding_boxes_00043.json',\n",
       " 'data/images/img__00045_.png': 'data/bounding_boxes/bounding_boxes_00044.json',\n",
       " 'data/images/img__00046_.png': 'data/bounding_boxes/bounding_boxes_00045.json',\n",
       " 'data/images/img__00047_.png': 'data/bounding_boxes/bounding_boxes_00046.json',\n",
       " 'data/images/img__00048_.png': 'data/bounding_boxes/bounding_boxes_00047.json',\n",
       " 'data/images/img__00049_.png': 'data/bounding_boxes/bounding_boxes_00048.json',\n",
       " 'data/images/img__00050_.png': 'data/bounding_boxes/bounding_boxes_00049.json',\n",
       " 'data/images/img__00051_.png': 'data/bounding_boxes/bounding_boxes_00050.json',\n",
       " 'data/images/img__00052_.png': 'data/bounding_boxes/bounding_boxes_00051.json',\n",
       " 'data/images/img__00053_.png': 'data/bounding_boxes/bounding_boxes_00052.json',\n",
       " 'data/images/img__00054_.png': 'data/bounding_boxes/bounding_boxes_00053.json',\n",
       " 'data/images/img__00055_.png': 'data/bounding_boxes/bounding_boxes_00054.json',\n",
       " 'data/images/img__00056_.png': 'data/bounding_boxes/bounding_boxes_00055.json',\n",
       " 'data/images/img__00057_.png': 'data/bounding_boxes/bounding_boxes_00056.json',\n",
       " 'data/images/img__00058_.png': 'data/bounding_boxes/bounding_boxes_00057.json',\n",
       " 'data/images/img__00059_.png': 'data/bounding_boxes/bounding_boxes_00058.json',\n",
       " 'data/images/img__00060_.png': 'data/bounding_boxes/bounding_boxes_00059.json',\n",
       " 'data/images/img__00061_.png': 'data/bounding_boxes/bounding_boxes_00060.json',\n",
       " 'data/images/img__00062_.png': 'data/bounding_boxes/bounding_boxes_00061.json',\n",
       " 'data/images/img__00063_.png': 'data/bounding_boxes/bounding_boxes_00062.json',\n",
       " 'data/images/img__00064_.png': 'data/bounding_boxes/bounding_boxes_00063.json',\n",
       " 'data/images/img__00065_.png': 'data/bounding_boxes/bounding_boxes_00064.json',\n",
       " 'data/images/img__00066_.png': 'data/bounding_boxes/bounding_boxes_00065.json',\n",
       " 'data/images/img__00067_.png': 'data/bounding_boxes/bounding_boxes_00066.json',\n",
       " 'data/images/img__00068_.png': 'data/bounding_boxes/bounding_boxes_00067.json',\n",
       " 'data/images/img__00069_.png': 'data/bounding_boxes/bounding_boxes_00068.json',\n",
       " 'data/images/img__00070_.png': 'data/bounding_boxes/bounding_boxes_00069.json',\n",
       " 'data/images/img__00071_.png': 'data/bounding_boxes/bounding_boxes_00070.json',\n",
       " 'data/images/img__00072_.png': 'data/bounding_boxes/bounding_boxes_00071.json',\n",
       " 'data/images/img__00073_.png': 'data/bounding_boxes/bounding_boxes_00072.json',\n",
       " 'data/images/img__00074_.png': 'data/bounding_boxes/bounding_boxes_00073.json',\n",
       " 'data/images/img__00075_.png': 'data/bounding_boxes/bounding_boxes_00074.json',\n",
       " 'data/images/img__00076_.png': 'data/bounding_boxes/bounding_boxes_00075.json',\n",
       " 'data/images/img__00077_.png': 'data/bounding_boxes/bounding_boxes_00076.json',\n",
       " 'data/images/img__00078_.png': 'data/bounding_boxes/bounding_boxes_00077.json',\n",
       " 'data/images/img__00079_.png': 'data/bounding_boxes/bounding_boxes_00078.json',\n",
       " 'data/images/img__00080_.png': 'data/bounding_boxes/bounding_boxes_00079.json',\n",
       " 'data/images/img__00081_.png': 'data/bounding_boxes/bounding_boxes_00080.json',\n",
       " 'data/images/img__00082_.png': 'data/bounding_boxes/bounding_boxes_00081.json',\n",
       " 'data/images/img__00083_.png': 'data/bounding_boxes/bounding_boxes_00082.json',\n",
       " 'data/images/img__00084_.png': 'data/bounding_boxes/bounding_boxes_00083.json',\n",
       " 'data/images/img__00085_.png': 'data/bounding_boxes/bounding_boxes_00084.json',\n",
       " 'data/images/img__00086_.png': 'data/bounding_boxes/bounding_boxes_00085.json',\n",
       " 'data/images/img__00087_.png': 'data/bounding_boxes/bounding_boxes_00086.json',\n",
       " 'data/images/img__00088_.png': 'data/bounding_boxes/bounding_boxes_00087.json',\n",
       " 'data/images/img__00089_.png': 'data/bounding_boxes/bounding_boxes_00088.json',\n",
       " 'data/images/img__00090_.png': 'data/bounding_boxes/bounding_boxes_00089.json',\n",
       " 'data/images/img__00091_.png': 'data/bounding_boxes/bounding_boxes_00090.json',\n",
       " 'data/images/img__00092_.png': 'data/bounding_boxes/bounding_boxes_00091.json',\n",
       " 'data/images/img__00093_.png': 'data/bounding_boxes/bounding_boxes_00092.json',\n",
       " 'data/images/img__00094_.png': 'data/bounding_boxes/bounding_boxes_00093.json',\n",
       " 'data/images/img__00095_.png': 'data/bounding_boxes/bounding_boxes_00094.json',\n",
       " 'data/images/img__00096_.png': 'data/bounding_boxes/bounding_boxes_00095.json',\n",
       " 'data/images/img__00097_.png': 'data/bounding_boxes/bounding_boxes_00096.json',\n",
       " 'data/images/img__00098_.png': 'data/bounding_boxes/bounding_boxes_00097.json',\n",
       " 'data/images/img__00099_.png': 'data/bounding_boxes/bounding_boxes_00098.json',\n",
       " 'data/images/img__00100_.png': 'data/bounding_boxes/bounding_boxes_00099.json'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data_dir = os.path.join(current_dir, 'data')\n",
    "images_dir = os.path.join(data_dir, 'img')\n",
    "bboxes_dir = os.path.join(data_dir, 'box')\n",
    "\n",
    "# Initialize the mapping dictionary\n",
    "image_to_bbox = {}\n",
    "\n",
    "# List and sort image files to ensure consistent order\n",
    "image_files = sorted(f for f in os.listdir(images_dir) if f.endswith('.png'))\n",
    "\n",
    "for image_file in image_files:\n",
    "    # Extract image number from filename (e.g., 'img__00001_.png' -> 1)\n",
    "    try:\n",
    "        image_num = int(image_file.split('__')[1].split('_')[0])\n",
    "    except (IndexError, ValueError):\n",
    "        print(f\"Skipping unrecognized image file format: {image_file}\")\n",
    "        continue\n",
    "\n",
    "    # Adjust for off-by-one indexing\n",
    "    bbox_num = image_num - 1\n",
    "    bbox_file = f\"bounding_boxes_{bbox_num:05d}.json\"\n",
    "\n",
    "    # Build absolute or relative paths as needed\n",
    "    image_path = os.path.join('data/images', image_file)\n",
    "    bbox_path = os.path.join('data/bounding_boxes', bbox_file)\n",
    "\n",
    "    # Add to mapping\n",
    "    image_to_bbox[image_path] = bbox_path\n",
    "\n",
    "imagedirmap = {}\n",
    "# Optional: Print or save mapping\n",
    "print(\"Image to bounding box mapping:\")\n",
    "for img, bbox in image_to_bbox.items():\n",
    "    # print(f\"{img} --> {bbox}\")\n",
    "    imagedirmap[img] = bbox\n",
    "\n",
    "imagedirmap\n",
    "# Optional: Save to JSON\n",
    "# with open('image_bbox_mapping.json', 'w') as f:\n",
    "#     json.dump(image_to_bbox, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8738f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_NAME = \"ViT-B/32\"\n",
    "SIMILARITY_THRESHOLD = 0.15  # tune this on a small validation set\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c931fed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): Sequential(\n",
       "        (0): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): ResidualAttentionBlock(\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): QuickGELU()\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): Sequential(\n",
       "      (0): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (2): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (4): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (6): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (8): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (9): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (10): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (11): ResidualAttentionBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): QuickGELU()\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, preprocess = clip.load(MODEL_NAME, device=DEVICE)\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLIP_img_obj_detect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
